{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Wavenet_separate.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "BN2e-VUR4Uu4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UkYou-rG5nE0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sound_path = '/content/gdrive/My Drive/learning/sound'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uBxnP8Gj6AbA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/lithium0003/sound_separation.git\n",
        "! cp sound_separation/ssWavenet/* .\n",
        "! ln -s \"{sound_path}\" sound"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TAIhw2rsFrKT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "! pip install pysoundfile\n",
        "! apt install libsndfile1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZXouzYxjDUgG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def load_config(config_filepath):\n",
        "    try:\n",
        "        config_file = open(config_filepath, 'r')\n",
        "    except IOError:\n",
        "        print('No readable config file at path: ' + config_filepath)\n",
        "        exit()\n",
        "    else:\n",
        "        with config_file:\n",
        "            return json.load(config_file)\n",
        "\n",
        "config = load_config('config.json')\n",
        "config['training']['batch_size'] = 128\n",
        "config['training']['path'] = 'sound/sessions/wavenet/001'\n",
        "\n",
        "targets = ['sound/data/cat/all01.wav',\n",
        "            'sound/data/cat/all02.wav',\n",
        "            ]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3d0NQPG_DZDX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "\n",
        "import models\n",
        "import datasets\n",
        "\n",
        "def get_valid_output_folder_path(outputs_folder_path):\n",
        "    j = 1\n",
        "    while True:\n",
        "        output_folder_name = 'samples_%d' % j\n",
        "        output_folder_path = os.path.join(outputs_folder_path, output_folder_name)\n",
        "        if not os.path.isdir(output_folder_path):\n",
        "            os.makedirs(output_folder_path, exist_ok=True)\n",
        "            break\n",
        "        j += 1\n",
        "    return output_folder_path\n",
        "\n",
        "\n",
        "def separate(config, targets):\n",
        "    model = models.SeparationWavenet(config)\n",
        "    batch_size = config['training']['batch_size']\n",
        "\n",
        "    samples_folder_path = os.path.join(config['training']['path'], 'samples')\n",
        "    output_path = get_valid_output_folder_path(samples_folder_path)\n",
        "\n",
        "    for target in targets:\n",
        "        print(target)\n",
        "        output_filename_prefix = os.path.basename(target)\n",
        "        output_filename_prefix = output_filename_prefix[0:-4]\n",
        "\n",
        "        sequence, sample_rate = datasets.read_wav(target)\n",
        "        mixture = sequence\n",
        "\n",
        "        num_output_samples = mixture.shape[0] - (model.receptive_field_length - 1)\n",
        "        num_fragments = int(np.ceil(num_output_samples / model.target_field_length))\n",
        "        num_batches = int(np.ceil(num_fragments / batch_size))\n",
        "\n",
        "        vocals_output = {}\n",
        "        for i in range(model.num_sources):\n",
        "            vocals_output[i] = []\n",
        "\n",
        "        num_pad_values = 0\n",
        "        fragment_i = 0\n",
        "\n",
        "        for batch_i in range(0, num_batches):\n",
        "            print('%d/%d'%(batch_i, num_batches))\n",
        "            \n",
        "            if batch_i == num_batches - 1:  # If its the last batch\n",
        "                batch_size = num_fragments - batch_i * batch_size\n",
        "\n",
        "            input_batch = np.zeros((batch_size, model.input_length))\n",
        "\n",
        "            # Assemble batch\n",
        "            for batch_fragment_i in range(0, batch_size):\n",
        "\n",
        "                if fragment_i + model.target_field_length > num_output_samples:\n",
        "                    remainder = mixture[fragment_i:]\n",
        "                    current_fragment = np.zeros((model.input_length,))\n",
        "                    current_fragment[:remainder.shape[0]] = remainder\n",
        "                    num_pad_values = model.input_length - remainder.shape[0]\n",
        "                else:\n",
        "                    current_fragment = mixture[fragment_i:fragment_i + model.input_length]\n",
        "\n",
        "                input_batch[batch_fragment_i, :] = current_fragment\n",
        "                fragment_i += model.target_field_length\n",
        "\n",
        "            separated_output_fragments = model.separate_batch({'data_input': input_batch})\n",
        "\n",
        "            for i in range(model.num_sources):\n",
        "                vocals_output_fragment = separated_output_fragments[i]\n",
        "                vocals_output_fragment = vocals_output_fragment[:,\n",
        "                                         model.target_padding: model.target_padding + model.target_field_length]\n",
        "                vocals_output_fragment = vocals_output_fragment.flatten().tolist()\n",
        "\n",
        "                vocals_output[i] = vocals_output[i] + vocals_output_fragment\n",
        "\n",
        "        for i in range(model.num_sources):\n",
        "            vocals_output[i] = np.array(vocals_output[i])\n",
        "            if num_pad_values != 0:\n",
        "                vocals_output[i] = vocals_output[i][:-num_pad_values]\n",
        "\n",
        "\n",
        "            output_vocals_filename = output_filename_prefix + '_vocals%d.wav'%(i+1)\n",
        "            output_vocals_filepath = os.path.join(output_path, output_vocals_filename)\n",
        "\n",
        "            datasets.write_wav(vocals_output[i], output_vocals_filepath, sample_rate)\n",
        "\n",
        "separate(config, targets)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
