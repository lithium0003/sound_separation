{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Wave-U-Net_separate.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "BN2e-VUR4Uu4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UkYou-rG5nE0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sound_path = '/content/gdrive/My Drive/learning/sound'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uBxnP8Gj6AbA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/lithium0003/sound_separation.git\n",
        "! cp sound_separation/WaveUNet/* .\n",
        "! ln -s \"{sound_path}\" sound"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TAIhw2rsFrKT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "! pip install pysoundfile\n",
        "! apt install libsndfile1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZXouzYxjDUgG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def load_config(config_filepath):\n",
        "    try:\n",
        "        config_file = open(config_filepath, 'r')\n",
        "    except IOError:\n",
        "        print('No readable config file at path: ' + config_filepath)\n",
        "        exit()\n",
        "    else:\n",
        "        with config_file:\n",
        "            return json.load(config_file)\n",
        "\n",
        "config = load_config('config.json')\n",
        "config['training']['batch_size'] = 16\n",
        "config['training']['path'] = 'sound/sessions/WaveUNet/001'\n",
        "\n",
        "targets = ['sound/data/cat/all01.wav',\n",
        "            'sound/data/cat/all02.wav',\n",
        "            ]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3d0NQPG_DZDX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "\n",
        "import models\n",
        "import datasets\n",
        "\n",
        "def get_valid_output_folder_path(outputs_folder_path):\n",
        "    j = 1\n",
        "    while True:\n",
        "        output_folder_name = 'samples_%d' % j\n",
        "        output_folder_path = os.path.join(outputs_folder_path, output_folder_name)\n",
        "        if not os.path.isdir(output_folder_path):\n",
        "            os.makedirs(output_folder_path, exist_ok=True)\n",
        "            break\n",
        "        j += 1\n",
        "    return output_folder_path\n",
        "\n",
        "\n",
        "def separate(config, targets):\n",
        "    model = models.UnetAudioSeparator(config)\n",
        "    batch_size = config['training']['batch_size']\n",
        "\n",
        "    samples_folder_path = os.path.join(config['training']['path'], 'samples')\n",
        "    output_path = get_valid_output_folder_path(samples_folder_path)\n",
        "\n",
        "    for target in targets:\n",
        "        print(target)\n",
        "        output_filename_prefix = os.path.basename(target)\n",
        "        output_filename_prefix = output_filename_prefix[0:-4]\n",
        "\n",
        "        sequence, sample_rate = datasets.read_wav(target)\n",
        "        mix_audio = sequence\n",
        "\n",
        "        source_time_frames = mix_audio.shape[0]\n",
        "        input_time_frames = model.input_num_samples\n",
        "        output_time_frames = model.output_num_samples\n",
        "\n",
        "        pad_time_frames = (input_time_frames - output_time_frames) // 2\n",
        "        mix_audio_padded = np.pad(mix_audio, [(pad_time_frames, pad_time_frames), (0,0)], mode=\"constant\", constant_values=0.0)\n",
        "\n",
        "        source_preds = [np.zeros(mix_audio.shape, np.float32) for _ in range(model.num_sources)]\n",
        "\n",
        "        batch_i = 0\n",
        "        input_batch = []\n",
        "        out_time = []\n",
        "\n",
        "        for source_pos in range(0, source_time_frames, output_time_frames):\n",
        "            print('%d/%d'%(source_pos, output_time_frames))\n",
        "            \n",
        "            if source_pos + output_time_frames > source_time_frames:\n",
        "                source_pos = source_time_frames - output_time_frames\n",
        "\n",
        "            mix_part = mix_audio_padded[source_pos:source_pos + input_time_frames,:]\n",
        "            out_time.append(range(source_pos, source_pos + output_time_frames))\n",
        "            input_batch.append(mix_part)\n",
        "            batch_i += 1\n",
        "\n",
        "            if batch_i == batch_size:\n",
        "                separated_output_fragments = model.separate_batch({'data_input': np.array(input_batch)})\n",
        "\n",
        "                for b in range(batch_size):\n",
        "                    for i in range(model.num_sources):\n",
        "                        source_preds[i][out_time[b]] = separated_output_fragments[i][b, :, :]\n",
        "\n",
        "                batch_i = 0\n",
        "                input_batch = []\n",
        "                out_time = []\n",
        "\n",
        "        if batch_i != 0:\n",
        "            for _ in range(batch_i, batch_size):\n",
        "                input_batch.append(np.zeros([input_time_frames,2], np.float32))\n",
        "\n",
        "            separated_output_fragments = model.separate_batch({'data_input': np.array(input_batch)})\n",
        "\n",
        "            for b in range(batch_i):\n",
        "                for i in range(model.num_sources):\n",
        "                    source_preds[i][out_time[b]] = separated_output_fragments[i][b, :, :]\n",
        "\n",
        "\n",
        "        for i in range(model.num_sources):\n",
        "            output_vocals_filename = output_filename_prefix + '_vocal%d.wav'%(i+1)\n",
        "            output_vocals_filepath = os.path.join(output_path, output_vocals_filename)\n",
        "\n",
        "            datasets.write_wav(source_preds[i], output_vocals_filepath, sample_rate)\n",
        "\n",
        "\n",
        "separate(config, targets)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
